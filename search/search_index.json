{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to my site","text":"<p>There is no linear system but only Taylor expansion.</p>"},{"location":"#my-doctoral-cap-is-built-with","title":"My doctoral cap is built with","text":""},{"location":"about/","title":"Dr.-Ing. Chao Yao","text":"<p> chao.yao@mail.de</p>"},{"location":"about/#education","title":"Education","text":"<ul> <li>Dr.-Ing. 2022 Control &amp; Robotics @Institut of Automation, TU Dresden, Germany</li> <li>Dipl.-Ing. 2015 Electrical Engineering @TU Dresden, Germany</li> <li>B.Sc. 2010 Automation @WUST, China</li> <li>B.B.A. 2010 Business Administration @WUST, China</li> </ul>"},{"location":"about/#experience","title":"Experience","text":"<ul> <li>Senior Robotics Software Engineer since 2024 @TII</li> <li>Robotic Software Developer 2022-2024 @B/S/H/</li> <li>Specialist Software Engineering Autonomous Drive 2021 @BMW</li> <li>Research &amp; Teaching Assistent 2015-2021 @TU Dresden</li> <li>Intern 2014 @Continental</li> </ul>"},{"location":"about/#research-topics","title":"Research Topics","text":"<ul> <li>Aerial Robotics</li> <li>Over-actuated Systems</li> <li>Fault-tolerant Control</li> <li>Nonlinear Observer Design</li> <li>Visual Inertial Odometry</li> </ul>"},{"location":"about/#expertise","title":"Expertise","text":"<p>Design, modeling, simulation and control of serial, mobile and aerial robots, SLAM, path planning, linear and nonlinear controller design, observer design, sensor fusion, state estimation, optimization algorithms artificial neural network, scientific writing, agile development, commercial software development process</p>"},{"location":"about/#languages","title":"Languages","text":"<ul> <li>Chinese Native</li> <li>English</li> <li>German</li> </ul>"},{"location":"about/#publications","title":"Publications","text":"<ul> <li>Yao, Chao. \u201cA Contribution to the Design of Highly Redundant Compliant Aerial Manipulation Systems,\u201d Vogt Verlag, Dresden, 2022. ISBN:978-3-95947-056-8.</li> <li>Shawky, David, Chao Yao, and Klaus Janschek. \u201cNonlinear Model Predictive Control for Trajectory Tracking of a Hexarotor with Actively Tiltable Propellers.\u201d In 2021 7<sup>th</sup> International Conference on Automation, Robotics and Applications (ICARA), 128\u201334, 2021. https://doi.org/10.1109/ICARA51699.2021.9376523.</li> <li>Yao, Chao, and Klaus Janschek. \u201cImpedance Control of an Aerial Manipulator Composed of a Multirotor and a 6-DOF Manipulator,\u201d VDI Mechatronik 2021, 2021.</li> <li>Yao, Chao Yao, Nils Dunkelberg and Klaus Janschek. \u201cTrajectory Generation and Tracking of a Hexarotor with Fixed Tilted Rotors Considering Bounded Rotor Velocity,\u201d 3<sup>rd</sup> International Symposium on Aerial Robotics, 2019.</li> <li>Zhu, Jinyao, Chao Yao, and Klaus Janschek. \u201cStereo Visual-Inertial Fusion for UAV State Estimation.\u201d IFAC-PapersOnLine, 21<sup>st</sup> IFAC World Congress, 53, no. 2 (January 1, 2020): 9420\u201325. https://doi.org/10.1016/j.ifacol.2020.12.2412.</li> <li>Yao, Chao, Micha Schuster, Zijian Jiang, Klaus Janschek, and Michael Beitelschmidt. \u201cSensitivity Analysis of Model-Based Impedance Control for Physically Interactive Hexarotor.\u201d IFAC-PapersOnLine, 8<sup>th</sup> IFAC Symposium on Mechatronic Systems MECHATRONICS 2019, 52, no. 15 (January 1, 2019): 597\u2013602. https://doi.org/10.1016/j.ifacol.2019.11.741.</li> <li>Schuster, Micha, David Bernstein, Chao Yao, Klaus Janscheck, and Michael Beitelschmidt. \u201cComparison of Design Approaches of Fully Actuated Aerial Robots Based on Maximum Wrench Generation and Minimum Energy Consumption.\u201d IFAC-PapersOnLine, 8<sup>th</sup> IFAC Symposium on Mechatronic Systems MECHATRONICS 2019, 52, no. 15 (January 1, 2019): 603\u20138. https://doi.org/10.1016/j.ifacol.2019.11.742.</li> <li>Wilmsen, Marek, Chao Yao, Micha Schuster, Shixiong Li, and Klaus Janschek. \u201cNonlinear Wrench Observer Design for an Aerial Manipulator.\u201d IFAC-PapersOnLine, 1<sup>st</sup> IFAC Workshop on Robot Control WROCO 2019, 52, no. 22 (January 1, 2019): 1\u20136. https://doi.org/10.1016/j.ifacol.2019.11.038.</li> <li>Schuster, Micha, David Bernstein, Chao Yao, Klaus Janschek, and Michael Beitelschmidt. \u201cWrench Space Based Design of Fully Actuated Aerial Robots,\u201d Mechatronik 2019, 2019.</li> <li>Yao, Chao, Jan Krieglstein, and Klaus Janschek. \u201cModeling and Sliding Mode Control of a Fully-Actuated Multirotor with Tilted Propellers.\u201d IFAC-PapersOnLine 51, no. 22 (2018): 115\u201320. https://doi.org/10.1016/j.ifacol.2018.11.527.</li> </ul>"},{"location":"blog/","title":"Blogs","text":"<p>{{ blog_content }}</p>"},{"location":"til/","title":"Today I Learned","text":"<p>{{ blog_content TIL}}</p>"},{"location":"blog/cpp/concurrency/","title":"Multithreading and Concurrency in C++","text":"<p>Multithreading is a feature that allows concurrent execution of two or more parts of a program for maximum utilization of the CPU. Multithreading support was introduced in C+11. </p> <p>Note</p> <p>Multiple threads may read from the same memory location while all other accesses (r-w,w-r and w-w) are called conflicts. Data races, deadlocks are undefined behavior.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#thread","title":"Thread","text":"","tags":["C++"]},{"location":"blog/cpp/concurrency/#launching-thread","title":"Launching Thread","text":"<p>The constructor of <code>std::thread</code> can be used to start a new thread. We simply need to pass the executing code to be called (i.e, a callable object). Once the object is created a new thread is launched which will execute the code specified in callable. A callable can be either of the three</p> <ul> <li>Function pointer</li> <li>Function object</li> <li>Lambda expression</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;thread&gt;\nvoid foo(int a, int b)\n{\n  std::cout &lt;&lt; \"Thread has ID: \" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;\n}\nclass bar\n{\n  // Overload () operator\n  void operator()(int c)\n  {\n      std::cout &lt;&lt; \"Thread has ID: \" &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;\n  }\n};\nint main()\n{\n  int a = 1;\n  int b = 2;\n  // Pass a function and args\n  std::thread t1(foo, a, b);\n  // Pass a lambda\n  std::thread t2([a, b](){ foo(a, b); });\n  // Pass a function object\n  std::thread t3(bar(), a);\n  // Execute in the main thread\n  foo(6, 7);\n  t3.join();\n  t2.join();\n  t1.join();\n}\n</code></pre> <p>Thread is movable but not copyable. <code>std::move</code> tansfers all resources associated with the running thread. The move-from thread becomes empty and not joinable, and only the move-to thread can be joined.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;string_view&gt;\n#include &lt;thread&gt;\nvoid foo(std::string_view s);\nint main()\n{\n  std::thread t1([]() { foo(\"Hi\\n\"); });\n  std::thread t2 = std::move(t1); // t1 is now empty\n  t2.join(); // OK, thread originally started in t1 is joined\n}\n</code></pre> <p>Thread can be used in standard library containers, e.g.</p> <pre><code>#include &lt;thread&gt;\n#include &lt;vector&gt;\nvoid foo(int i);\nint main()\n{\n  std::vector&lt;std::thread&gt; threadPool;\n  for (int i = 1; i &lt;= 9; ++i)\n  {\n    threadPool.emplace_back([i]() { foo(i); });\n  }\n  // Digits 1 to 9 are printed (unordered)\n  for (auto&amp; t : threadPool)\n  {\n    t.join();\n  }\n}\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#join-and-detach","title":"Join and Detach","text":"<p>The thread will terminate once the function returns. The member function <code>join()</code> can be used to wait for a thread to finish. This function makes the current thread wait until the thread identified by <code>*this</code> has finished executing. It must be called exactly once for each thread.</p> <p>Alternatively, a thread can be detached for the thread object with <code>detach()</code>. The thread object can be destroyed and the OS thread of execution can continue on. If the program needs to know when that thread of execution has completed, some other mechanism needs to be used. <code>join()</code> cannot be called on that thread object any more, since it is no longer associated with a thread of execution.</p> <p><code>join()</code> or <code>detach()</code> must be called before a thread object is destroyed. It is considered an error to destroy a C++ thread object while it is still \"joinable\". If a C++ thread object is still joinable when it's destroyed, an exception will be thrown.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;string_view&gt;\n#include &lt;thread&gt;\nvoid foo(std::string_view s);\nint main() {\n{\n  std::thread t1([]() { foo(\"Hi\\n\"); });\n  t1.join();\n}\n// Everything is fine, we called t1.join()\n{\n  std::thread t2([]() {});\n}\n// Program terminated because t2 is joinable when destroyed\n}\n</code></pre> <p>Both API can be called only on a joinable thread. It can be checked with <code>joinable()</code> before calling <code>joint()</code> or <code>detach()</code>.</p> <pre><code>std::thread th(foo, args);\nif (th.joinable())\n{\n  th.detach();\n}\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#manage-the-current-thread","title":"Manage the Current Thread","text":"API C++ Version Description yield C++11 suggests that the implementation reschedule execution of threads get_id C++11 returns the thread id of the current thread (OS specific) sleep_for C++11 blocks the execution of the current thread for at least the specified sleep_duration. sleep_until C++11 blocks the execution of the current thread until specified sleep_time has been reached. <p>Each thread object has an associated ID <code>std::thread::id</code> which can be get by <code>std::thread::get_id()</code>. <code>std::this_thread::get_id()</code> returns the ID of the current thread. If a thread object has no associated thread, <code>get_id()</code> will return \"not any thread\"</p> <p>Note</p> <p>In the example, the arguments are passed by value. If you pass by reference, the life time of the variable has to be considered. The thread kann exceed its lifetime, which leads to access a destroyed object.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#call_once","title":"Call_once","text":"<p>In some use cases, we want to executes the Callable object exactly once, even if called concurrently, from several threads. For instance, you have to do a not-thread-safe one-time global initialization before you're able to do some thread-safe stuff. You can use <code>call_once</code> that calls the initialization only once, no matter in which thread and whether it's called concurrently.</p> <pre><code>void init()\n{\n  std::cout &lt;&lt; \"Initializing...\" &lt;&lt; std::endl;\n  // Do something\n}\n\nvoid worker(once_flag* flag)\n{\n  call_once(*flag, init);\n}\n\nint main()\n{\n  once_flag flag;\n  std::vector&lt;std::thread&gt; threadPool;\n  for (int i = 1; i &lt;= 9; ++i)\n  {\n    threadPool.push_back(std::thread(worker, &amp;flag));\n  }\n  for (auto&amp; t : threadPool)\n  {\n    t.join();\n  }\n}\n</code></pre> <p>In this example, all 9 threads will call <code>init</code> once. We don't know which thread has called the init function but it doesn't matter.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#critical-section-and-race-condition","title":"Critical Section and Race Condition","text":"<p>A critical section is a section of code that is executed by multiple threads and where the sequence of execution for the threads makes a difference in the result of the concurrent execution of the critical section.</p> <p>A race condition is a situation that may occur inside a critical section. This happens when the result of multiple thread execution in critical section differs according to the order in which the threads execute. The term race condition stems from the metaphor that the threads are racing through the critical section, and that the result of that race impacts the result of executing the critical section. Race conditions can be extremely difficult to debug simply because the bug itself depends on the timing of nondeterministic events. It is quite common that the bug cannot be recreated by testers, particularly if the problematic timing results from a rare circumstance.</p> <p>Story</p> <p>The Therac-25 radiation therapy machine is a classic and well-cited example of a race condition with deadly effects. The software for this machine included a one-byte counter. If the machine\u2019s operator entered terminal input to the machine at the exact moment that the counter overflowed (quite common for a counter with only 256 possible values), a critical safety lock failed. This flaw made it possible for patients to receive approximately 100 times the intended radiation dose, which directly caused the deaths of three patients. <sup>1</sup></p> <p>Let's try the following example. Five threads are launched to add 1000 respectively to a shared account object. The initial amount is 0 and the expected amount is 5000 when all the threads are finished.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;thread&gt;\n\nclass Account\n{\npublic:\n  Account() : mMoney(0) {}\n  int getMoney()\n  {\n    return mMoney;\n  }\n  void addMoney(int money)\n  {\n    for (auto i = 0; i &lt; money; i++) {\n      mMoney++;\n    }\n  }\n\nprivate:\n  int mMoney;\n};\n\nint testMultiThreadAccount()\n{\n  Account myAccountObj;\n  std::vector&lt;std::thread&gt; threadpool;\n  // 5 thread to add 1000 to myAccountobj in each.\n  for (auto i = 0; i &lt; 5; i++) {\n    threadpool.push_back(std::thread(&amp;Account::addMoney, &amp;myAccountObj, 1000));\n  }\n  for (auto&amp; t : threadpool) {\n    t.join();\n  }\n  return myAccountObj.getMoney();\n}\n\nint main()\n{\n  int value;\n  for (int i = 0; i &lt; 1000; i++) {\n    value = testMultiThreadAccount();\n    if (value != 5000) {\n      std::cout &lt;&lt; \"Error at run = \" &lt;&lt; i &lt;&lt; \", Money in accout = \" &lt;&lt; value &lt;&lt; std::endl;\n    }\n  }\n  return 0;\n}\n</code></pre> <p>The result is sometimes less than the expectation due to race condition.</p> <pre><code>Error at run = 302, Money in accout = 4651\nError at run = 540, Money in accout = 4985\nError at run = 625, Money in accout = 4000\nError at run = 662, Money in accout = 4000\nError at run = 809, Money in accout = 4379\nError at run = 816, Money in accout = 4993\nError at run = 821, Money in accout = 4879\nError at run = 837, Money in accout = 2000\nError at run = 875, Money in accout = 4823\nError at run = 881, Money in accout = 4701\nError at run = 911, Money in accout = 4118\nError at run = 949, Money in accout = 4000\n</code></pre> <p>As we know, for modern processors, in order to speed up processing, each processor has multi-level Cache as shown in the following figure. The cache is involved when the processor is performing calculations, such as reading and writing data. It is possible that there is an inconsistency between the cache and the main memory of the system. That is, a result is computed and saved in the processor's cache, but not yet synchronized to the main memory, and this value is not visible to other processors.</p> <p></p> <p>Actually, the statement <code>mMoney++</code> is not atomic. It is actually a combination of many instructions to accomplish. Let's say that on a particular device, this statement is accomplished by 3 machine commands and their timing may be as follows:</p> <p></p> <p>In this case, an increment will be ignored, because instead of increasing the mMoney variable twice, a different register is added and the value of the \"mMoney\" variable is overwritten.</p> <p>Naturally, we can now understand that the race condition occurs because these threads are accessing the shared data at the same time, and the changes made by some of them are not made known to the other threads, causing the other threads to process on the wrong basis, and the result is naturally wrong. Avoiding race conditions requires data protection for critical sections. If we let only one thread access the shared data at a time, and let other threads access it afterwards, the problem can be solved.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#mutex-and-lock","title":"Mutex and Lock","text":"","tags":["C++"]},{"location":"blog/cpp/concurrency/#mutual-exclusion","title":"Mutual Exclusion","text":"<p>Mutual exclusion is a straightforward way to synchronize multiple threads, thus, avoid race conditions.</p> <ul> <li>Threads acquire a lock on a mutex object before entering a critical section.</li> <li>Threads release their lock on the mutex when leaving a critical section.</li> </ul> <p>In the c++, mutexes are in the <code>&lt;mutex&gt;</code> header file, and there are mainly 6 classes:</p> API C++ version Description mutex C++11 basic mutual exclusion timed_mutex C++11 with timeout recursive_mutex C++11 can be recursively locked by the same thread recursive_timed_mutex C++11 recursive mutex with timeout shared_timed_mutex C++14 shared mutex with timeout shared_mutex C++17 several threads can share ownership of the same mutex <p>All mutex classes have three basic member functions:</p> <p>|lock|locks the mutex, blocks if the mutex is not available| |try_lock|tries to lock the mutex, returns if the mutex is not available| |unlock|unlocks the mutex|</p> <p>Other classes are extended with following features:</p> <ul> <li>timeout provides <code>try_lock_for</code> and <code>try_lock_until</code> methods. If the lock is not acquired within the time limit, it will return directly and will not wait any longer.</li> <li>recursive The same lock can be locked multiple times in the same thread. This avoids some unnecessary deadlocks.</li> <li>share has two levels of access. <code>shared</code>: several threads can share ownership of the same mutex. <code>exclusive</code>: only one thread can own the mutex.</li> <li>If one thread has acquired the exclusive lock (through <code>lock</code>, <code>try_lock</code>), no other threads can acquire the lock (including the shared).</li> <li>If one thread has acquired the shared lock (through <code>lock_shared</code>, <code>try_lock_shared</code>), no other thread can acquire the exclusive lock, but can acquire the shared lock.</li> </ul> <p>In practice, high-level programming model is designed like this:</p> <ul> <li>The resource (usually a class) that requires protection from data races owns a mutex object of the appropriate type.</li> <li>Threads that intend to access the resource acquire a suitable lock on the mutex before performing the actual access.</li> <li>Threads release their lock on the mutex after completing the access.</li> <li>Usually locks are simply acquired and released in the member functions of the class.</li> </ul> <p>Next, let's fix the example code with mutex. We have only to modify the <code>Account</code> class and lock in the shared function <code>addMoney</code>:</p> <pre><code>class Account\n{\npublic:\n  Account() : mMoney(0) {}\n  int getMoney()\n  {\n    return mMoney;\n  }\n  void addMoney(int money)\n  {\n    exclusive.lock();\n    for (auto i = 0; i &lt; money; i++) {\n      mMoney++;\n    }\n    exclusive.unlock();\n  }\n\nprivate:\n  int mMoney;\n  std::mutex exclusive;\n};\n</code></pre> <p>In the example, we have manually locked and unlocked the mutex. This is not an easy task in a complicated nested structure considering exception. What happens if we forget to release the lock at the end of the function? In this case, one thread will exit without releasing the lock and the other threads will remain waiting. To avoid this, we should use <code>std::lock_guard</code>.</p> <p>The class lock_guard is a mutex wrapper that provides a convenient RAII-style mechanism for owning a mutex for the duration of a scoped block. When a lock_guard object is created, it attempts to take ownership of the mutex it is given. When control leaves the scope in which the lock_guard object was created, the lock_guard is destructed and the mutex is released.</p> <pre><code>class Account\n{\npublic:\n  Account() : mMoney(0) {}\n  int getMoney()\n  {\n    return mMoney;\n  }\n  void addMoney(int money)\n  {\n        std::lock_guard&lt;std::mutex&gt; lockGuard(exclusive);\n    for (auto i = 0; i &lt; money; i++) {\n      // In case of exception, destructor of lock_guard will be called\n      mMoney++;\n    }\n    // destructor of lock_guard will be called to unlock mutex\n  }\n\nprivate:\n  int mMoney;\n  std::mutex exclusive;\n};\n</code></pre> <p>If you compared the example using 5 threads with a serial version, it performs much worse than the single thread program.</p> <p>WHY?</p> <p>It is costly to add and unlock locks. The most time-consuming part of the computation here is inside the lock, which can only be executed by one thread at a time serially, compared to the single-threaded model, the example is not only serial, but also increases the burden of lock, and thus slower.</p> <p>The data we divide to each thread is actually independent and time consuming for data processing, but in fact this part of the logic can be handled separately by each thread and there is no need to add locks. Only one lock at the end when aggregating the data will be sufficient. To improve the performance, we modify the member function as</p> <pre><code>void addMoney(int money)\n{\n  int tmp =0;\n  for (auto i = 0; i &lt; money; i++) {\n    tmp++;\n  }\n  std::lock_guard&lt;std::mutex&gt; lockGuard(exclusive);\n  mMoney += tmp;\n}\n</code></pre> <p>The for-loop is parallalized and the example outperforms the single thread version. We describe the scope of a lock in terms of its granularity. Fine-grained means that the lock protects a small range, and coarse-grained means that the lock protects a large range. For performance reasons, we should ensure that the lock is as fine-grained as possible. Also, time-consuming operations, such as IO, should not be performed within the scope of the lock, and if the computation is time-consuming, it should be moved outside the lock as much as possible.</p> <p>Quote</p> <p>In general, a lock should be held for only the minimum possible time needed to perform the required operations. \u2013\u300aC++ Concurrency in Action\u300b</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#raii-wrappers","title":"RAII Wrappers","text":"<p>Besides <code>lock_guard</code>, the standard library provides RAII wrappers for locking and unlocking mutexes</p> API C++ version Description lock_guard C++11 implements a strictly scope-based mutex ownership wrapper unique_lock C++11 implements movable mutex ownership wrapper shared_lock C++11 implements movable shared mutex ownership wrapper scoped_lock C++11 deadlock-avoiding RAII wrapper for multiple mutexes <p>Tip</p> <p>The RAII wrappers should always be preferred for locking and unlocking mutexes, since it makes bugs due to inconsistent locking/unlocking much more unlikely.</p> <p>The full name of RAII is Resource Acquisition Is Initialization. RAII is a C++ programming technique that ties the life cycle of resources that must be requested before they can be used (e.g., allocated heap memory, threads of execution, open sockets, open files, locked mutexes, disk space, database connections, etc.) to the life cycle of an object. RAII ensures that resources are available to any function that will access the object. It also ensures that all resources are released in reverse order of acquisition at the end of the lifetime of the object they control. Similarly, if the resource acquisition fails (the constructor exits with an exception), all resources acquired for the constructed object and base class subobjects are released in reverse order of initialization. This effectively eliminate memory leaks and ensure exception safety.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#unique_lock","title":"Unique_lock","text":"<p><code>std::unique_lock</code> provides additional constructors</p> <ul> <li>unique_lock(mutex_type&amp; m, std::defer_lock_t t) \u2013 Do not immediately lock the mutex</li> <li>unique_lock(mutex_type&amp; m, std::try_to_lock_t t) \u2013 Do not block when the mutex cannot be locked</li> </ul> <p>std::unique_lock provides additional member functions</p> <ul> <li>lock() \u2013 Manually lock the mutex</li> <li>try_lock() \u2013 Try to lock the mutex, return true if successful</li> <li>operator bool() \u2013 Check if the std::unique_lock holds a lock on the mutex</li> </ul> <pre><code>#include &lt;mutex&gt;\nstd::mutex mutex;\nvoid foo()\n{\n  std::unique_lock lock(mutex, std::try_to_lock);\n  if (!lock)\n  {\n    // do unsynchronized work here\n\n    lock.lock(); // block until we can get the lock\n  }\n\n  // do synchronized work here;\n\n  lock.unlock(); // release the lock early\n\n  // do unsynchronized work here\n}\n</code></pre> <p>The difference between <code>lock_guard</code> and <code>unique_lock</code> is that you can lock and unlock a <code>std::unique_lock</code>. <code>std::lock_guard</code> will be locked only once on construction and unlocked on destruction. <code>unique_lock</code> also provides the feature e.g., be constructed without locking the mutex immediately. <code>lock_guard</code> cannot lock multiple mutexes safely.</p> <p>Note</p> <p>Since C++17, one should use <code>std::scoped_lock</code> instead of <code>std::lock_guard</code>.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#shared_lock","title":"Shared_lock","text":"<p>std::shared_lock can be used to lock a mutex in shared mode</p> <ul> <li>Constructors and member functions analogous to std::unique_lock</li> <li>Multiple threads can acquire a shared lock on the same mutex</li> <li>Shared locking attempts block if the mutex is locked in exclusive mode</li> <li>Only usable in conjunction with std::shared_mutex</li> </ul> <p>Note</p> <p>Shared mutexes are mostly used to implement read/write-locks. Only read accesses are allowed when holding a shared lock while write accesses are only allowed when holding an exclusive lock.</p> <pre><code>#include &lt;shared_mutex&gt;\nclass SafeCounter\n{\nprivate:\n  mutable std::shared_mutex mutex;\n  size_t value = 0;\n  public:\n  size_t getValue() const\n  {\n    std::shared_lock lock(mutex);\n    return value; // read access\n  }\n\n  void incrementValue()\n  {\n    std::unique_lock lock(mutex);\n    ++value; // write access\n  }\n};\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#scoped_lock","title":"Scoped_lock","text":"<p><code>Scoped_lock</code> locks a mutex for its lifetime and unlocks it when it is destroyed. Also, it can lock multiple mutexes and avoid deadlocks.</p> <pre><code>#include &lt;chrono&gt;\n#include &lt;functional&gt;\n#include &lt;iostream&gt;\n#include &lt;mutex&gt;\n#include &lt;string&gt;\n#include &lt;thread&gt;\n#include &lt;vector&gt;\nusing namespace std::chrono_literals;\n\nstruct Employee\n{\n  std::vector&lt;std::string&gt; lunch_partners;\n  std::string id;\n  std::mutex m;\n  Employee(std::string id) : id(id) {}\n  std::string partners() const\n  {\n    std::string ret = \"Employee \" + id + \" has lunch partners: \";\n    for (const auto&amp; partner : lunch_partners)\n      ret += partner + \" \";\n    return ret;\n  }\n};\n\nvoid send_mail(Employee &amp;, Employee &amp;)\n{\n  // simulate a time-consuming messaging operation\n  std::this_thread::sleep_for(1s);\n}\n\nvoid assign_lunch_partner(Employee &amp;e1, Employee &amp;e2)\n{\n  static std::mutex io_mutex;\n  {\n    std::lock_guard&lt;std::mutex&gt; lk(io_mutex);\n    std::cout &lt;&lt; e1.id &lt;&lt; \" and \" &lt;&lt; e2.id &lt;&lt; \" are waiting for locks\" &lt;&lt; std::endl;\n  }\n\n  {\n    // use std::scoped_lock to acquire two locks without worrying about\n    // other calls to assign_lunch_partner deadlocking us\n    // and it also provides a convenient RAII-style mechanism\n\n    std::scoped_lock lock(e1.m, e2.m);\n\n    // Equivalent code 1 (using std::lock and std::lock_guard)\n    // std::lock(e1.m, e2.m);\n    // std::lock_guard&lt;std::mutex&gt; lk1(e1.m, std::adopt_lock);\n    // std::lock_guard&lt;std::mutex&gt; lk2(e2.m, std::adopt_lock);\n\n    // Equivalent code 2 (if unique_locks are needed, e.g. for condition variables)\n    // std::unique_lock&lt;std::mutex&gt; lk1(e1.m, std::defer_lock);\n    // std::unique_lock&lt;std::mutex&gt; lk2(e2.m, std::defer_lock);\n    // std::lock(lk1, lk2);\n    {\n        std::lock_guard&lt;std::mutex&gt; lk(io_mutex);\n        std::cout &lt;&lt; e1.id &lt;&lt; \" and \" &lt;&lt; e2.id &lt;&lt; \" got locks\" &lt;&lt; std::endl;\n    }\n    e1.lunch_partners.push_back(e2.id);\n    e2.lunch_partners.push_back(e1.id);\n  }\n\n  send_mail(e1, e2);\n  send_mail(e2, e1);\n}\n\nint main()\n{\n  Employee alice(\"Alice\"), bob(\"Bob\"), christina(\"Christina\"), dave(\"Dave\");\n\n  // assign in parallel threads because mailing users about lunch assignments\n  // takes a long time\n  std::vector&lt;std::thread&gt; threads;\n  threads.emplace_back(assign_lunch_partner, std::ref(alice), std::ref(bob));\n  threads.emplace_back(assign_lunch_partner, std::ref(christina), std::ref(bob));\n  threads.emplace_back(assign_lunch_partner, std::ref(christina), std::ref(alice));\n  threads.emplace_back(assign_lunch_partner, std::ref(dave), std::ref(bob));\n\n  for (auto &amp;thread : threads)\n      thread.join();\n  std::cout &lt;&lt; alice.partners() &lt;&lt; '\\n'  &lt;&lt; bob.partners() &lt;&lt; '\\n'\n            &lt;&lt; christina.partners() &lt;&lt; '\\n' &lt;&lt; dave.partners() &lt;&lt; '\\n';\n}\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#deadlocks","title":"Deadlocks","text":"<p>The following example will lead to deadlocks\uff1a</p> <pre><code>std::mutex m1, m2, m3;\nvoid threadA()\n{\n  // INTENTIONALLY BUGGY\n  std::unique_lock l1{m1}, l2{m2}, l3{m3};\n}\nvoid threadB()\n{\n  // INTENTIONALLY BUGGY\n  std::unique_lock l3{m3}, l2{m2}, l1{m1};\n}\n</code></pre> <p>Possible deadlock scenario:</p> <ul> <li>threadA() acquires locks on m1 and m2</li> <li>threadB() acquires lock on m3</li> <li>threadA() waits for threadB() to release m3</li> <li>threadB() waits for threadA() to release m2</li> </ul> <p><code>std::scoped_lock</code> RAII wrapper can be used to safely lock any number of mutexes:</p> <pre><code>std::mutex m1, m2, m3;\nvoid threadA()\n{\n  // OK, will not deadlock\n  std::scoped_lock l{m1, m2, m3};\n}\nvoid threadB()\n{\n  // OK, will not deadlock\n  std::scoped_lock l{m3, m2, m1};\n}\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#condition-variables","title":"Condition Variables","text":"<p>A condition variable is a synchronization primitive that allows multiple threads to wait until an (arbitrary) condition becomes true.</p> <ul> <li>A condition variable uses a mutex to synchronize threads</li> <li>Threads can wait on or notify the condition variable</li> <li>When a thread waits on the condition variable, it blocks until another thread notifies it</li> <li>If a thread waited on the condition variable and is notified, it holds the mutex</li> <li>A notified thread must check the condition explicitly because spurious wake-ups can occur</li> </ul> <p>Class <code>std::condition_variable</code> in the header <code>&lt;condition_variable&gt;</code> has the following member functions:</p> <ul> <li>wait(): Takes a reference to a std::unique_lock that must be locked by the caller as an argument, unlocks the mutex and waits for the condition variable</li> <li>notify_one(): Notify a single waiting thread, mutex does not need to be held by the caller</li> <li>notify_all(): Notify all waiting threads, mutex does not need to be held by the caller</li> </ul> <pre><code>#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;thread&gt;\n#include &lt;mutex&gt;\n#include &lt;condition_variable&gt;\n\nstd::mutex m;\nstd::condition_variable cv;\nstd::string data;\nbool ready = false;\nbool processed = false;\n\nvoid worker_thread()\n{\n    // Wait until main() sends data\n    std::unique_lock lk(m);\n    cv.wait(lk, []{return ready;});\n\n    // after the wait, we own the lock.\n    std::cout &lt;&lt; \"Worker thread is processing data\" &lt;&lt; std::endl;\n    data += \" after processing\";\n\n    // Send data back to main()\n    processed = true;\n    std::cout &lt;&lt; \"Worker thread signals data processing completed\" &lt;&lt; std::endl;\n\n    // Manual unlocking is done before notifying, to avoid waking up\n    // the waiting thread only to block again (see notify_one for details)\n    lk.unlock();\n    cv.notify_one();\n}\n\nint main()\n{\n  std::thread worker(worker_thread);\n\n  data = \"Example data\";\n  // send data to the worker thread\n  {\n    std::lock_guard lk(m);\n    ready = true;\n    std::cout &lt;&lt; \"main() signals data ready for processing\" &lt;&lt; std::endl;\n  }\n  cv.notify_one();\n\n  // wait for the worker\n  {\n    std::unique_lock lk(m);\n    cv.wait(lk, []{return processed;});\n  }\n  std::cout &lt;&lt; \"Back in main(), data = \" &lt;&lt; data &lt;&lt; std::endl;\n\n  worker.join();\n}\n</code></pre> <p>Output:</p> <pre><code>main() signals data ready for processing\nWorker thread is processing data\nWorker thread signals data processing completed\nBack in main(), data = Example data after processing\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#future","title":"Future","text":"<p>The standard library provides facilities to obtain values that are returned and to catch exceptions that are thrown by asynchronous tasks (i.e. functions launched in separate threads). These values are communicated in a shared state, in which the asynchronous task may write its return value or store an exception, and which may be examined, waited for, and otherwise manipulated by other threads that hold instances of std::future or std::shared_future that reference that shared state.</p> API C++ version Description async C++11 Run a function asynchronously and return a std::future with its result future C++11 waits for a value that is set asynchronously packaged_task C++11 packages a function to store its return value for asynchronous retrieval promise C++11 stores a value for asynchronous retrieval shared_future C++11 similar to std::future, except that multiple threads are allowed to wait for the same shared state.","tags":["C++"]},{"location":"blog/cpp/concurrency/#promise-and-future","title":"promise and future","text":"<p>Question</p> <p>We often encounter situations where we need to get the result returned by a thread, how we can implement it?</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#share-with-pointer","title":"Share with Pointer","text":"<p>We can pass a pointer to a new thread in which the result will be set. The main thread will wait via condition variables. The new thread then sets the result and notifies the condition variable, the main thread will get the result from that pointer. To implement this simple feature, we use a condition variable, a mutex lock, and a pointer to capture the return value.</p> <p>If we want the thread to return multiple different values at different points in time, the problem becomes more complex. Is there an easy way to get the return value from the thread? The answer is to use std::future</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#c11-promise-and-future","title":"C++11 <code>promise</code> and <code>future</code>","text":"<p><code>std::future</code> is a class template whose objects store future values. In fact, a <code>std::future</code> object stores internally a value that will be assigned in the future, and provides a mechanism to access that value, implemented through the member function <code>get()</code>. But if someone tries to access the value through it before the <code>get()</code> function is available, then the it will block until that value is available. <code>std::promise</code> provides a facility to store a value or an exception that is later acquired asynchronously via a <code>std::future</code> object created by the <code>std::promise</code> object.</p> <p>Each <code>std::promise</code> object has a corresponding <code>std::future</code> object, through which others can get the value set by the <code>promise</code>. For instance,</p> <ol> <li>thread 1 creates a <code>std::promise</code> object and then get the <code>std::future</code> object from it.</li> <li>thread 1 passes it to thread 2.</li> <li>Thread 1 will get the value set by thread 2 through the <code>get()</code> of <code>std::future</code>.</li> <li>If thread 2 has not yet set the value, the <code>get()</code> call will block until thread 2 sets the value in the <code>promise</code> object.</li> </ol> <p></p> <p>Here is a complete example of <code>std::future</code> and <code>std::promise</code>.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;thread&gt;\n#include &lt;future&gt;\n#include &lt;chrono&gt;\n\nvoid doWork(std::promise&lt;int&gt; promiseObj)\n{\n  std::cout &lt;&lt; \"Inside new thread\" &lt;&lt; std::endl;\n  std::this_thread::sleep_for(std::chrono::seconds(5));\n  promiseObj.set_value(7);  // set value that can be accessed by future1\n}\n\nint main()\n{\n  std::promise&lt;int&gt; promise1;\n  std::future&lt;int&gt; future1 = promise1.get_future();\n  std::thread th(doWork, std::move(promise1));\n  std::cout &lt;&lt; \"Main thread call get() for result... \" &lt;&lt; std::endl;\n  int result = future1.get();  // blocked here until promise1 is set in the new thread\n  std::cout &lt;&lt; \"Result is returned: \" &lt;&lt; result &lt;&lt; std::endl;\n  th.join();\n  return 0;\n}\n</code></pre>","tags":["C++"]},{"location":"blog/cpp/concurrency/#async","title":"async","text":"<p>The function template <code>async</code> runs a function asynchronously (potentially in a separate thread which might be a part of a thread pool) and returns a <code>std::future</code> that will eventually hold the result of that function call.</p> <p>The first parameter in <code>std::async</code> is the launch policy, which controls the asynchronous behavior.</p> Bit Description std::launch::async enable asynchronous evaluation (separate thread) std::launch::deferred enable lazy evaluation std::launch::async | std::launch::deferred asynchronously or not, depending on the system load (default) <p>If more than one flag is set, it is implementation-defined which policy is selected. For the default (both the std::launch::async and std::launch::deferred flags are set in policy), standard recommends (but doesn't require) utilizing available concurrency, and deferring any additional tasks.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;cmath&gt;\n#include &lt;thread&gt;\n#include &lt;future&gt;\n\nclass Worker\n{\npublic:\n  Worker(int min, int max) : mMin(min), mMax(max) {}  // \u2460\n  double work()\n  {  //\n    mResult = 0;\n    for (int i = mMin; i &lt;= mMax; i++) {\n      mResult += std::sqrt(i);\n    }\n    return mResult;\n  }\n  double getResult()\n  {\n    return mResult;\n  }\n\nprivate:\n  int mMin;\n  int mMax;\n  double mResult;\n};\n\nint main()\n{\n  Worker w(0, 10e8);\n  std::cout &lt;&lt; \"Task in class triggered\" &lt;&lt; std::endl;\n  auto f3 = std::async(std::launch::async, &amp;Worker::work, &amp;w);  //\n  f3.wait();\n  std::cout &lt;&lt; \"Task in class finish, result: \" &lt;&lt; w.getResult() &lt;&lt; std::endl &lt;&lt; std::endl;\n\n  return 0;\n}\n</code></pre> <p>Attention</p> <p>Note that a pointer to the object <code>&amp;w</code> is passed. If you do not write <code>&amp;</code> a temporary copy of the object <code>w</code> will be passed in.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#packaged_task","title":"packaged_task","text":"<p>The class template <code>std::packaged_task</code> wraps any Callable target (function, lambda expression, bind expression, or another function object) so that it can be invoked asynchronously. Its return value or exception thrown is stored in a shared state which can be accessed through <code>std::future</code> objects.</p> <pre><code>#include &lt;iostream&gt;\n#include &lt;cmath&gt;\n#include &lt;thread&gt;\n#include &lt;future&gt;\n#include &lt;functional&gt;\n\n// unique function to avoid disambiguating the std::pow overload set\nint f(int x, int y) { return std::pow(x,y); }\n\nvoid task_lambda()\n{\n  std::packaged_task&lt;int(int,int)&gt; task([](int a, int b) {\n      return std::pow(a, b);\n  });\n  std::future&lt;int&gt; result = task.get_future();\n\n  task(2, 9);\n\n  std::cout &lt;&lt; \"task_lambda:\\t\" &lt;&lt; result.get() &lt;&lt; '\\n';\n}\n\nvoid task_bind()\n{\n  std::packaged_task&lt;int()&gt; task(std::bind(f, 2, 11));\n  std::future&lt;int&gt; result = task.get_future();\n\n  task();\n\n  std::cout &lt;&lt; \"task_bind:\\t\" &lt;&lt; result.get() &lt;&lt; '\\n';\n}\n\nvoid task_thread()\n{\n  std::packaged_task&lt;int(int,int)&gt; task(f);\n  std::future&lt;int&gt; result = task.get_future();\n\n  std::thread task_td(std::move(task), 2, 10);\n  task_td.join();\n\n  std::cout &lt;&lt; \"task_thread:\\t\" &lt;&lt; result.get() &lt;&lt; '\\n';\n}\n\nint main()\n{\n  task_lambda();\n  task_bind();\n  task_thread();\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n#include &lt;cmath&gt;\n#include &lt;thread&gt;\n#include &lt;future&gt;\n#include &lt;vector&gt;\n\nusing namespace std;\n\nstatic const int MAX = 10e8;\n\ndouble concurrent_worker(int min, int max)\n{\n  double sum = 0;\n  for (int i = min; i &lt;= max; i++) {\n    sum += sqrt(i);\n  }\n  return sum;\n}\n\ndouble concurrent_task(int min, int max)\n{\n  vector&lt;future&lt;double&gt;&gt; results;  // future list to store results\n\n  unsigned concurrent_count = thread::hardware_concurrency();\n  min = 0;\n  for (int i = 0; i &lt; concurrent_count; i++) {\n    packaged_task&lt;double(int, int)&gt; task(concurrent_worker);  // package task\n    results.push_back(task.get_future());                     // store associated future objects\n\n    int range = max / concurrent_count * (i + 1);\n    thread t(std::move(task), min, range);  // launch new thread\n    t.detach();\n\n    min = range + 1;\n  }\n\n  cout &lt;&lt; \"threads create finish\" &lt;&lt; endl;\n  double sum = 0;\n  for (auto&amp; r : results) {\n    sum += r.get();  // add results up\n  }\n  return sum;\n}\n\nint main()\n{\n  auto start_time = chrono::steady_clock::now();\n  double r = concurrent_task(0, MAX);\n  auto end_time = chrono::steady_clock::now();\n  auto ms = chrono::duration_cast&lt;chrono::milliseconds&gt;(end_time - start_time).count();\n  cout &lt;&lt; \"Concurrent task finish, \" &lt;&lt; ms &lt;&lt; \" ms consumed, Result: \" &lt;&lt; r &lt;&lt; endl;\n  return 0;\n}\n</code></pre> <p>In real projects, you can package tasks into queues with the help of <code>packaged_task</code> and then schedule them by means of thread pools.</p> <p></p> <p>A <code>packaged_task</code> won't start on it's own, you have to invoke it. On the other hand, <code>std::async</code> with <code>launch::async</code> will try to run the task in a different thread. By using <code>std::async</code> you cannot run your task on a specific thread anymore, where <code>std::packaged_task</code> can be moved to other threads.</p> <p>In the end a <code>std::packaged_task</code> is just a lower level feature for implementing <code>std::async</code> (which is why it can do more than <code>std::async</code> if used together with other lower level stuff, like <code>std::thread</code>). Simply spoken a <code>std::packaged_task</code> is a <code>std::function</code> linked to a <code>std::future</code> and <code>std::async</code> wraps and calls a <code>std::packaged_task</code> (possibly in a different thread).</p> <p>Tldr</p> <p>Use <code>std::async</code> if you want some things done and don't really care when they're done, and <code>std::packaged_task</code> if you want to wrap up things in order to move them to other threads or call them later.</p>","tags":["C++"]},{"location":"blog/cpp/concurrency/#parallel-stl","title":"Parallel STL","text":"<p>With C++17, most of the algorithms of the Standard Template Library will be available in a parallel version. Therefore, you can invoke an algorithm with a so-called execution policy. This execution policy specifies if the algorithm runs sequential (<code>std::seq</code>), parallel (<code>std::par</code>), or parallel and vectorised (<code>std::par_unseq</code>).</p> <pre><code>std::vector&lt;int&gt; vec ={3, 2, 1, 4, 5, 6, 10, 8, 9, 4};\n\nstd::sort(vec.begin(), vec.end());                            // sequential as ever\nstd::sort(std::execution::seq, vec.begin(), vec.end());       // sequential\nstd::sort(std::execution::par, vec.begin(), vec.end());       // parallel\nstd::sort(std::execution::par_unseq, vec.begin(), vec.end()); // parallel and vectorized\n</code></pre> <p>Therefore, the first and second variations of the sort algorithm run sequential, the third parallel, and the fourth parallel and vectorised.</p> <p>C++20 offers totally new multithreading concepts. The key idea is that multithreading becomes a lot simpler and less error-prone.</p> <ol> <li> <p>https://en.wikipedia.org/wiki/Therac-25\u00a0\u21a9</p> </li> </ol>","tags":["C++"]},{"location":"blog/git/bisect/","title":"Find Bug-introducing Commit","text":"","tags":["git"]},{"location":"blog/git/bisect/#what-is-git-bisect","title":"What is git bisect","text":"<p>Git bisect uses a binary search algorithm to find which commit in your project\u2019s history that changed any property of your project, normally the one introduced a specific bug.</p>","tags":["git"]},{"location":"blog/git/bisect/#how-to-use-git-bisect","title":"How to use git bisect","text":"<p>Basic git bisect commands are start, good, bad. As an example, let's assume that the commit history is \"... 0 ... 100\". A feature is broken at the current commit 100, but is known to work at commit 0 (commit/tag). We want to figure out with the help of git bisect, which commit introduced the bug. We can start a bisect session and specify the bad and good commit:</p> <p><pre><code>git bisect start\ngit bisect bad  # Current commit is bad\ngit bisect good 0  # Commit 0 is good\n</code></pre> Git bisect will start the binary search by checking out the commit in the middle of the range.</p> <p>For the example, it will checkout commit 50. We can build the code and test whether the feature is broken. Tell bisect the result and it will carry on the binary search, and it will check out the next commit in the middle of the left range that needs testing. Repeat this procedure until no more commit left to inspect. Git bisect will print out a description of the first bad commit. The reference <code>refs/bisect/bad</code> will be left pointing to it.</p> <p>To clean up bisect session and return to the original HEAD, use</p> <pre><code>git bisect reset\n</code></pre> <p>By default, git will return to the commit that was checked out before <code>git bisect start</code>.  It is possible to return to a specific commit with</p> <pre><code>git bisect reset &lt;commit&gt;\n</code></pre> <p>Note</p> <p>When a new bisect session starts, it will clean up the old bisection state.</p>","tags":["git"]},{"location":"blog/git/bisect/#alternate-terms","title":"Alternate terms","text":"<p>When we looking for the commit caused a changed instead of breaking a feature, using the terms \"good\" and \"bad\" is confusing. Alternatively, \"old\" and \"new\" can be used. <pre><code>git bisect start\ngit bisect old\ngit bisect new\n</code></pre></p> <p>You can even customize the term by starting with</p> <pre><code>git bisect start --term-new foo --term-old bar\ngit bisect bar\ngit bisect foo\n</code></pre>","tags":["git"]},{"location":"blog/git/bisect/#visualization","title":"Visualization","text":"<p>To see the currently remaining suspects in <code>gitk</code></p> <pre><code>git bisect view\n</code></pre>","tags":["git"]},{"location":"blog/git/lfs/","title":"Git Large File Storage (LFS)","text":"","tags":["git"]},{"location":"blog/git/lfs/#what-is-git-lfs","title":"What is Git LFS","text":"<p>Git Large File Storage (LFS) is a open souce git extension, which replaces large and binary files such as audio samples, videos, datasets, and graphics with text pointers inside git. And it stores the file content on a remote server, outside the git protocol (which is not designed for large files).</p> <p>Per default remote servers like Github or Gitlab have file size limit at several MegaBytes while the maximum file size in Git LFS is 5GB. If you regularly push large or binary files, you should consider introducing Git LFS as part of your workflow. In best case, enable LFS while creating the git repository.</p>","tags":["git"]},{"location":"blog/git/lfs/#install-git-lfs","title":"Install Git LFS","text":"<p>Download and run the installation script.</p> <p><pre><code>curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n</code></pre> Set up Git LFS for your user account by running the command below.. You only need to run this once per user account.</p> <pre><code>git lfs install\n</code></pre> <p>Note</p> <p>The settings will be saved in the file <code>.gitattributes</code>.</p>","tags":["git"]},{"location":"blog/git/lfs/#track-large-files","title":"Track Large Files","text":"<p>In each Git repositiry, configure Git LFS to manage a specific file type (e.g., .mov and .bin). Alternatively, you can directly edit your <code>.gitattributes</code>.</p> <pre><code>git lfs track *.mov\ngit lfs track \"*.bin\"\n</code></pre> <p>Configure Git LFS to track only files in a specific directory:</p> <pre><code>git lfs track 'images/'\n</code></pre> <p>Check which file types are currently under Git LFS:</p> <pre><code>git lfs track\n</code></pre> <p>Note</p> <p>Note that defining the file types to be tracked will not, by itself, convert any pre-existing files to Git LFS, such as files on other branches or in your prior commit history. Only from that point in time when you added it, the files will be stored to the external storage. To do that, use the <code>git lfs migrate</code> command, which has a range of options designed to suit various potential use cases.</p> <p>Make sure the config file is tracked.</p> <pre><code>git add .gitattributes\n</code></pre> <p>You can then commit and push to remote git repositories as normal, e.g.,</p> <pre><code>git add example.mov\ngit commit -m \"Add video file.\"\ngit push origin develop\n</code></pre>","tags":["git"]},{"location":"blog/git/lfs/#untrack-large-files","title":"Untrack Large Files","text":"<p>To remove files from tracking:</p> <pre><code>git lfs untrack '&lt;file-type&gt;'\ngit rm --cached '&lt;file-type&gt;'\ngit add '&lt;file-type&gt;'\ngit commit -m \"restore '&lt;file-type&gt;' to git from lfs\"\n</code></pre>","tags":["git"]},{"location":"blog/git/lfs/#migrate-existing-non-lfs-repositories","title":"Migrate Existing Non-LFS Repositories","text":"<p>As the way to migrate depends on the version of your git lfs, it\u2019s described very detailed here.</p> <p>Create a bare clone of the repository</p> <pre><code>git clone --bare https://&lt;old_repository&gt;.git\n\nPull in the repository\u2019s Git Large File Storage objects\n\n```bash\ncd old_repository.git &amp;&amp; git lfs fetch --all\n</code></pre> <p>Mirror-push to the new repository</p> <pre><code>git push --mirror https://&lt;new-repository&gt;.git +\n# If you have files which are larger than 50 MB, you will get an error if you have files which exceed file size limit.\n</code></pre> <p>Push the repository\u2019s Git LFS objects to your mirror</p> <pre><code>git lfs push --all https://&lt;new-repository&gt;.git\n</code></pre> <p>Remove the temporary local repository you created earlier</p> <pre><code>cd .. &amp;&amp; rm -rf &lt;old-repository&gt;.git\n</code></pre>","tags":["git"]},{"location":"blog/robotics/lie_group/","title":"Lie Group for 3D Rigid Transformation","text":"<p>The modeling and control of mobile robotic systems involve rigid transformations in the 3D geometry. This article addresses two Lie groups for 3D transformations with some basic properties.</p> <p> </p> Representation of the relation between the Lie group and the Lie algebra. <p>The Lie algebra (see the following Figure) is the tangent space associated with a Lie group generated by differentiating the group transformations along with chosen directions at the identity transformation. The Lie algebra \\(T_{\\varepsilon}\\mathcal{M}\\) (red plane) is the tangent space to the Lie group\u2019s manifold \\(\\mathcal{M}\\) (here represented as a blue sphere) at the identity \\(\\varepsilon\\). The sphere in \\(\\mathbb{R}^3\\) is in fact not a Lie group but used as an intuitive representation.</p> <p>Through the exponential map shown in the Figure, each straight path \\(\\mathbf{v}t\\) through the origin on the Lie algebra produces a path \\(\\exp \\left( \\mathbf{v}t \\right)\\) around the manifold which runs along the respective geodesic. Conversely, each element of the group has an equivalent in the Lie algebra. The complicated nonlinear Lie group is nearly completely determined by the associated Lie algebra, which is a linear vector space, and its Lie bracket. This relation is so profound that almost all operations in the group, which is curved and nonlinear, have an exact equivalent in the Lie algebra, which is a linear vector space. For instance, velocities of transformations are well represented in the tangent space. The orientation of a rigid body in 3D space can be described by the special orthogonal group SO(3), and the position and orientation by the special Euclidean group SE(3).</p> <p>Elements of SO(3) are represented by \\(3 \\times 3\\) rotation matrices. Transformation composition and inversion in the group correspond to matrix multiplication and inversion. Since rotation matrices are orthogonal, transposition is equivalent to inversion. $$ \\mathrm{SO}(3) = {\\mathbf{R} \\in \\mathbb{R}^{3\\times 3} |  \\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}_3,  \\det(\\mathbf{R})=1} $$</p> <p>Let $ \\mathbf{v} \\in \\mathbb{R}^3 $ denote the position of a point, the rotational transformation between {A} and {B} is expressed as $$  {^{A}}\\mathbf{v} = {^{A}{B}}\\mathbf{R}\\, {^{B}}\\mathbf{v} , \\quad {^{A}(3) \\enspace , $$ where the rotation matrix }}\\mathbf{R} \\in \\mathrm{SO\\({^{A}_{B}\\negthinspace}\\mathbf{R}\\) represents the coordinate transformation from the lower index, frame {B}, to the upper index, frame {A}. SO(3) is the three-dimensional special orthogonal group, which consists of all rotations about the origin of \\(\\mathbb{R}^3\\), defined as \\(\\mathrm{SO}(3) = \\{\\mathbf{R} \\in \\mathbb{R}^{3\\times 3}\\ | \\ \\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}_3, \\det(\\mathbf{R})=1\\}\\).</p> <p>The Lie algebra, so(3), is the set of $ 3 \\times 3 $ skew-symmetric matrices constructed by a vector \\(\\mathbf{\\omega} \\in \\mathbb{R}^3\\): $$ \\left[ \\mathbf{\\omega} \\right]_{\\times} = \\begin{bmatrix} 0 &amp; -\\omega_3 &amp; \\omega_2\\ \\omega_3 &amp; 0 &amp; -\\omega_1\\ -\\omega_2 &amp; \\omega_1 &amp; 0 \\end{bmatrix} \\enspace . $$</p> <p>SE(3) comprises arbitrary combinations of translations and rotations. The elements of SE(3) are \\(4 \\times 4\\) homogeneous transformation matrices that represent the position and orientation of a body relative to a reference frame. $$ \\mathrm{SE}(3) = \\begin{bmatrix} \\mathrm{SO}(3) &amp; \\mathbb{R}^3 \\ \\mathbf{0}_{1\\times3} &amp; 1 \\ \\end{bmatrix} $$</p> <p>Same as in SO(3), transformation composition and inversion correspond to matrix multiplication and inversion. $$ \\mathbf{T}_1,  \\mathbf{T}_2 \\in \\mathrm{SE}(3) $$ $$ \\mathbf{T}_1 \\cdot \\mathbf{T}_2 = \\begin{bmatrix} \\mathbf{R}_1 &amp; \\mathbf{p}_1\\ \\mathbf{0} &amp; 1\\ \\end{bmatrix} \\cdot \\begin{bmatrix} \\mathbf{R}_2 &amp; \\mathbf{p}_2\\ \\mathbf{0} &amp; 1\\ \\end{bmatrix} = \\begin{bmatrix} \\mathbf{R}_1 \\mathbf{R}_2 &amp; \\mathbf{R}_1 \\mathbf{p}_2 + \\mathbf{p}_1\\ \\mathbf{0} &amp; 1\\ \\end{bmatrix} $$ $$ \\mathbf{T}_1^{-1} = \\begin{bmatrix} \\mathbf{R}_1^\\top &amp; -\\mathbf{R}_1^\\top \\mathbf{p}_1\\ \\mathbf{0} &amp; 1\\ \\end{bmatrix} $$</p> <p>The group action on 3D vector \\(\\mathbf{v} = \\begin{bmatrix} x &amp; y &amp; z &amp; 1 \\end{bmatrix}\\) is given by $$ {^{A}}\\mathbf{v} = {^{A}{B}}\\mathbf{T}\\, {^{B}}\\mathbf{v} , \\quad  {^{A}(3) \\enspace . $$}}\\mathbf{T} \\in \\mathrm{SE</p> <p>The Lie algebra se(3) is the set of \\(4 \\times 4\\) matrices corresponding to differential translations and rotations: $$ \\left[ \\begin{array}{c|c} \\left[ \\mathbf{\\omega} \\right]{\\times} &amp; \\mathbf{\\upsilon}\\ \\hline \\mathbf{0} &amp; 0 \\end{array} \\right] \\in \\mathrm{se(3)} $$ where \\(\\mathbf{\\upsilon}, \\ \\mathbf{\\omega}\\) are vectors in \\(\\mathbb{R}^3\\).</p>"},{"location":"blog/server/config_ssh/","title":"SSH Configuration for Easy and Secure Remote Login","text":"<p>The most common way to login to a remote server is via SSH in a terminal. Four main steps will be shown here.\\</p> <ol> <li>Client config for fast login</li> <li>Public key for password-free login</li> <li>Disable password for security</li> <li>Change default port for security</li> <li>Stay connected</li> </ol>","tags":["SSH"]},{"location":"blog/server/config_ssh/#fast-ssh","title":"Fast SSH","text":"<p>In order to login to a remote server with the IP <code>192.168.0.8</code> as <code>chao</code>, we can use the following ssh command.</p> <pre><code>ssh chao@192.168.0.8\n</code></pre> <p>It is sometimes hard to remember the IP address of every remote server, and typing IP address is not efficient.\\ You can add hosts to <code>~/.ssh/config</code> on the client machine.</p> <pre><code># ~/.ssh/config\nHost nas\n    HostName 192.168.0.8\n    User chao\n</code></pre> <p>Consequently, you can use the host alias to login to the remote server more conveniently avoiding username and IP address.</p> <pre><code>ssh nas\n</code></pre>","tags":["SSH"]},{"location":"blog/server/config_ssh/#password-free-ssh","title":"Password-free SSH","text":"<p>By storing the public key of the client on the server <code>~/.ssh/authorized_keys</code>, you can get rid of entering password every time.</p> <p>If there is no ssh-key pair available yet in <code>~/.ssh/</code>, you can generate one with</p> <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre> <p>When you're prompted to \"Enter a file in which to save the key\", you can press Enter to accept the default file location. Press Enter again if you want to skip password for the key.</p> <p>To copy the client public key to the remote server, you can use <code>ssh-copy-id</code></p> <pre><code>ssh-copy-id nas\n\n# From now on, you can login to the server from this client without password.\nssh nas\n</code></pre>","tags":["SSH"]},{"location":"blog/server/config_ssh/#disable-password-login","title":"Disable Password Login","text":"<p>To protect the server from password leakage, a good practice is disabling password login and accept only connections from authorized hosts whose public keys are store on the server.  You can disable the password login in <code>/etc/ssh/sshd_config</code> on the server.</p> <pre><code># /etc/ssh/sshd_config\n\nPasswordAuthentication no\n</code></pre>","tags":["SSH"]},{"location":"blog/server/config_ssh/#change-default-port","title":"Change Default Port","text":"<p>By default, SSH servers run on port number 22. However, probing through default ports is usually the first step attackers take when seeking open SSH server ports. The main advantage of switching to a non-standard port is limiting brute force attacks and port scanner access to your server. You can change the port in <code>/etc/ssh/sshd_config</code> on the server.</p> <pre><code># /etc/ssh/sshd_config\n\nPort 2222\n\n# You have to specify port for ssh\nssh -p 2222 nas\n</code></pre> <p>You can specify the port in <code>~/.ssh/config</code> on the client to be faster:</p> <pre><code># ~/.ssh/config\nHost nas\n    HostName 192.168.0.8\n    User chao\n    Port 2222\n</code></pre>","tags":["SSH"]},{"location":"blog/server/config_ssh/#disable-root-login","title":"Disable Root Login","text":"<p>users can SSH to the server as <code>root</code> by default. This allows full access to and control over the entire system. To disable root user login, update SSH config file <code>/etc/ssh/sshd_config</code> and set option <code>PermitRootLogin</code> to <code>no</code> as below:</p> <pre><code># /etc/ssh/sshd_config\nPermitRootLogin no\n</code></pre> <p>Sudo users can still do root tasks even when root login is disabled.</p>","tags":["SSH"]},{"location":"blog/server/config_ssh/#stay-connected","title":"Stay Connected","text":"<p>You can specify the connection timeout in <code>~/.ssh/config</code> on the client:</p> <pre><code># ~/.ssh/config\nHost nas\n    HostName 192.168.0.8\n    User chao\n    Port 2222\n    ServerAliveInterval 60\n</code></pre>","tags":["SSH"]},{"location":"blog/sh/file_test_operators/","title":"Bash File Test Operators","text":"<p>We often need to check files or folders in a bash script. Following are file test operators in bash.\\</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-a","title":"-a","text":"<p>Returns <code>true</code> if file exists.</p> <p>Note</p> <p>It is identical in effect to <code>-e</code>, but it is deprecated and its use is discouraged.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-b","title":"-b","text":"<p>Returns <code>true</code> if file is a block device.</p> <p>Note</p> <p>A block device (e.g., hard drives, CDROM drives, flash drives) reads and/or writes data in chunks, or blocks, in contrast to a character device (e.g., keyboards, modems, sound cards), which acesses data in character units.</p> <pre><code>device=\"/dev/sda2\"\nif [ -b \"$device\" ]\nthen\n  echo \"$device is a block device.\"\nfi\n\n# /dev/sda2 is a block device.\n</code></pre>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-c","title":"-c","text":"<p>Returns <code>true</code> if file is a character device.</p> <pre><code>device1=\"/dev/ttyS1\"   # PCMCIA modem card.\nif [ -c \"$device1\" ]\nthen\n  echo \"$device1 is a character device.\"\nfi\n\n# /dev/ttyS1 is a character device.\n</code></pre>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-d","title":"-d","text":"<p>Returns <code>true</code> if file is a directory.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-e","title":"-e","text":"<p>Returns <code>true</code> if file exists.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-f","title":"-f","text":"<p>Returns <code>true</code> if file is a <code>regular</code> file, i.e., not a device file or a directory.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-g","title":"-g","text":"<p>Returns <code>true</code> if set-group-id (sgid) flag set on file or directory.\\ If a directory has the <code>sgid</code> flag set, then a file created within that directory belongs to the group that owns the directory, not necessarily to the group of the user who created the file. This may be useful for a directory shared by a workgroup.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-g_1","title":"-G","text":"<p>Returns <code>true</code> if <code>group-id</code> of the file is same as you.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-h","title":"-h","text":"<p>Returns <code>true</code> if file is a symbolic link.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-l","title":"-L","text":"<p>Returns <code>true</code> if file is a symbolic link.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-n","title":"-N","text":"<p>Returns <code>true</code> if file is modified since last read.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-o","title":"-O","text":"<p>Returns <code>true</code> if you are the owner of the file.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-p","title":"-p","text":"<p>Returns <code>true</code> if file is a pipe.</p> <p>Note</p> <p>Passes the output (stdout) of a previous command to the input (stdin) of the next one, or to the shell. This is a method of chaining commands together.</p> <pre><code>function show_input_type()\n{\n   [ -p /dev/fd/0 ] &amp;&amp; echo PIPE || echo STDIN\n}\n\nshow_input_type \"Input\"                           # STDIN\necho \"Input\" | show_input_type                    # PIPE\n\n# This example courtesy of Carl Anderson.\n</code></pre>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-s","title":"-s","text":"<p>Returns <code>true</code> if file is not zero size.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-s_1","title":"-S","text":"<p>Returns <code>true</code> if file is a socket.</p> <p>Note</p> <p>A socket is a communications node associated with a specific I/O port. (This is analogous to a hardware socket, or receptacle, for a connecting cable.) It permits data transfer between hardware devices on the same machine, between machines on the same network, between machines across different networks, and, of course, between machines at different locations on the Internet.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-t","title":"-t","text":"<p>Returns <code>true</code> if file is associated with a terminal device.\\ This test option may be used to check whether the <code>stdin</code> [ -t 0 ] or stdout [ -t 1 ] in a given script is a terminal.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-u","title":"-u","text":"<p>Returns <code>true</code> if set-user-id (suid) flag set on file</p> <p>Note</p> <p>A binary owned by root with set-user-id flag set runs with root privileges, even when an ordinary user invokes it. This is useful for executables (such as pppd and cdrecord) that need to access system hardware. Lacking the suid flag, these binaries could not be invoked by a non-root user.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-w","title":"-w","text":"<p>Returns <code>true</code> if file has write permission (for the user running the test).</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#-x","title":"-x","text":"<p>Returns <code>true</code> if file has execute permission (for the user running the test).</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#f1-nt-f2","title":"f1 -nt f2","text":"<p>Returns <code>true</code> if file <code>f1</code> is newer than <code>f2</code>.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#f1-ot-f2","title":"f1 -ot f2","text":"<p>Returns <code>true</code> if file <code>f1</code> is older than <code>f2</code>.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#f1-ef-f2","title":"f1 -ef f2","text":"<p>Returns <code>true</code> if files <code>f1</code> and <code>f2</code> are hard links to the same file.</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#_1","title":"!","text":"<p>\"not\" -- reverses the sense of the tests above (returns true if condition absent).</p>","tags":["Bash"]},{"location":"blog/sh/file_test_operators/#example","title":"Example","text":"<pre><code>#!/bin/bash\n# fileinfo.sh\n\nFILES=\"/usr/sbin/accept\n/usr/sbin/pwck\n/usr/sbin/chroot\n/usr/bin/fakefile\n/sbin/badblocks\n/sbin/ypbind\"     # List of files you are curious about.\n                  # Threw in a dummy file, /usr/bin/fakefile.\n\necho\n\nfor file in $FILES\ndo\n\n  if [ ! -e \"$file\" ]       # Check if file exists.\n  then\n    echo \"$file does not exist.\"; echo\n    continue                # On to next.\n   fi\n</code></pre>","tags":["Bash"]},{"location":"blog/vscode/extentsions/","title":"Recommended VS Code Extensions for Robotic Software Developers","text":"","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#c-extension-pack","title":"C++ Extension Pack","text":"<p>This extension pack includes</p> <ul> <li>C/C++</li> <li>C/C++ Themes</li> <li>CMake</li> <li>CMake Tools</li> </ul>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#cc","title":"C/C++","text":"<p>It provides language support for C/C++ to Visual Studio Code, including editing (IntelliSense) and debugging features.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#cc-themes","title":"C/C++ Themes","text":"<p>C++ color themes.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#cmake","title":"CMake","text":"<p>This extension provides support for CMake in Visual Studio Code including colorization and completion lists, etc.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#cmake-tools","title":"CMake Tools","text":"<p>It provides a full-featured, convenient, and powerful workflow for CMake-based projects in Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#code-runner","title":"Code Runner","text":"<p>Run code snippet or code file for multiple languages directly. You can e.g., run your .cpp file per one click.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#dev-containers","title":"Dev Containers","text":"<p>The Dev Containers extension lets you use a Docker container as a full-featured development environment. You can also enable your local extensions in dev containers.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#docker","title":"Docker","text":"<p>The Docker extension makes it easy to build, manage, and deploy containerized applications from Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#doxygen-documentation-generator","title":"Doxygen Documentation Generator","text":"<p>It helps to generate Doxygen documentation with comment block.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#drawio-integration","title":"Draw.io Integration","text":"<p>This extension integrates Draw.io into Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#gitlens","title":"GitLens","text":"<p>It enables more useful features to git in VS Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#indent-rainbow","title":"indent-rainbow","text":"<p>This extension colorizes the indentation in front of your text, alternating four different colors on each step.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#isort","title":"isort","text":"<p>A Visual Studio Code extension that provides import sorting using isort.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#markdown-all-in-one","title":"Markdown All in One","text":"<p>All you need for Markdown (keyboard shortcuts, table of contents, auto preview and more).</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#markdownlint","title":"Markdownlint","text":"<p>Markdown/CommonMark linting and style checking for Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#path-intellisense","title":"Path Intellisense","text":"<p>Visual Studio Code plugin that autocompletes filenames.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#plantuml","title":"PlantUML","text":"<p>It adds PlantUML support to Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#project-manager","title":"Project Manager","text":"<p>It helps you to easily access your projects, no matter where they are located.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#pylance","title":"Pylance","text":"<p>Pylance is an extension that works alongside Python in Visual Studio Code to provide performant language support.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#python","title":"Python","text":"<p>It adds language support for Python in Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#todo-tree","title":"Todo Tree","text":"<p>This extension quickly searches (using ripgrep) your workspace for comment tags like TODO and FIXME, and displays them in a tree view in the activity bar. The view can be dragged out of the activity bar into the explorer pane (or anywhere else you would prefer it to be).</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#trailing-spaces","title":"Trailing Spaces","text":"<p>A VS Code extension that allows you to highlight trailing spaces and delete them in a flash!</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#vscode-icons","title":"vscode-icons","text":"<p>Bring real icons to your Visual Studio Code.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#xml","title":"XML","text":"<p>This VS Code extension provides support for creating and editing XML documents, based on the LemMinX XML Language Server.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#yaml","title":"YAML","text":"<p>Provides comprehensive YAML Language support to Visual Studio Code, via the yaml-language-server, with built-in Kubernetes syntax support.</p>","tags":["C++","vscode"]},{"location":"blog/vscode/extentsions/#rainbow-csv","title":"Rainbow CSV","text":"<p>Highlight columns in comma (.csv), tab (.tsv), semicolon and pipe.</p>","tags":["C++","vscode"]},{"location":"projects/","title":"Index","text":""},{"location":"projects/#projects","title":"Projects","text":"01.2021 - present Homecare Robot B/S/H/, Germany 06.2018 - 09.2021 Flying Manipulator TU Dresden, Germany 08.2015 - 03.2017 Teching Robots in Saxony TU Dresden, Germany 12.2014 - 05.2015 Image Recongnition and Processing for Navigation TU Dresden, Germany 06.2013 - 09.2013 Small Linear and Planar Direct Drives TU Dresden. Germany 03.2009 - 08.2009 National University Students Intelligent Car Race WUST, China"},{"location":"projects/flypulator/","title":"FLYing maniPULATOR","text":""},{"location":"projects/flypulator/#summary","title":"Summary","text":"<p>Conceptual and technology development for aerial manipulation with free fyling fully actuated multicopters.</p>"},{"location":"projects/flypulator/#description","title":"Description","text":"<p>Aim of the Flypulator project is the development of flight robots for manipulation of stationary objects. Possible application scenarios include cleaning tasks and vegetation trimming in hardly accessible places. The development is focused on fully actuated flight robots. Due to their high agility, they allow the use of lightweight manipulators with small degree of freedom. The most important fields of activity are the construction of the hardware, the development and implementation of the control system and a detailed modelling including aerodynamical simulations and experiments.<sup>1</sup></p> <p>One of the lastest results was presented by Shuster et al. at IROS 2022 (see the video).</p>"},{"location":"projects/flypulator/#contributions","title":"Contributions","text":"<ul> <li>Tilt-Hexarotor prototype</li> <li>Motion tracking system based on VIVE Tracker.</li> <li>Kinematic and dynamic models for the Tilt-Hexarotor</li> <li>Nonlinear controllability and control authority for the semi-fully-actuated aerial vehicle.</li> <li>Simulation framework in Simulink and Gazebo.</li> <li>controllers (feedback linearization, SMC, backstepping, etc.) and observers (KF, EKF) design and implemented in Matlab and ROS</li> <li>Visual inertial odometer (Stereo extension of VINS-Mono)</li> </ul> Design of the aerial manipulator <p>Video: Omnidirectional UAV Demo</p> <p>Video: Aerial Manipulator Flying Demo</p> <p>Video: VINS-Stereo Test in Campus Building BAR</p> <p>Video: VINS-Stereo Outdoor Test</p> <p>Prototype with fixed rotors: IROS video</p> <ol> <li> <p>https://tu-dresden.de/ing/maschinenwesen/ifkm/dmt/forschung/projekte/Flypulator\u00a0\u21a9</p> </li> </ol>"},{"location":"projects/freescale/","title":"National University Students Intelligent Car Race","text":""},{"location":"projects/freescale/#desciption","title":"Desciption","text":"<p>In order to strengthen the cultivation of practical, innovative ability and team spirit of college students and promote the teaching reform of higher education, the National University Students Intelligent Car Race is organized by the Committee of Automation Teaching of the Ministry of Education. This competition is a creative science and technology competition with intelligent vehicles as the research object.</p> <p>The competition process includes theoretical design, actual production, vehicle debugging and on-site competition, which requires students to form a team and work together to experience the whole process of an engineering research and development project from design to realization.</p> <p>Since 2008, the competition has been approved by the Ministry of Education as one of the science and technology humanities competitions in the National Teaching Quality and Teaching Reform Project, and in 2009, the fourth edition was invited to apply for inclusion in the National Teaching Quality and Teaching Reform Project. In principle, the National Students Intelligent Car Race is entered by higher education institutions with automation majors nationwide. The competition is firstly registered and preliminarily held in each sub-region, and the winning teams of each sub-region will participate in the national finals. According to the teams and players of each competition, there are several competition groups such as photoelectric group, camera group, electromagnetic group, etc.</p> <p>In the competition Freescale's 8-bit and 16-bit microcontrollers are used as the core control unit on the specified model car platform with the aim to identify the road independently with sensors, motor drive circuits and the corresponding software, and to travel according to the specified route. The winner is the one with the shortest running time. The competition thus covers a wide range of disciplines such as control, pattern recognition, perception, electronics, electricity, computer science, and mechanics.</p>"},{"location":"projects/freescale/#contributions","title":"Contributions","text":"<ul> <li>Design of MCU board, motor drive board and sensor carring board</li> <li>Selection of sensors</li> <li>Mechanic construction</li> <li>Sensor drivers</li> <li>Controller design and tuning</li> </ul> Intelligent cars built by 4 teams at WUST Arena of the national final"},{"location":"projects/irpn/","title":"Image Recongnition and Processing for Navigation","text":""},{"location":"projects/irpn/#summary","title":"Summary","text":"<p>Design, development and verification of the necessary capabilities in image processing for position, pose and angular motion detection on uncooperative targets in an Active Debris Removal scenario.</p>"},{"location":"projects/irpn/#description","title":"Description","text":"<p>ESA has identified Active Debris Removal as a strategic goal, as it is necessary to stabilise the growth of space debris. This activity covers the gap for the capabilities needed in image processing using cameras in the visual and Infrared range of the spectrum and LIDAR sensors for precise estimation of position, pose and angular motion on uncooperative targets in an Active Debris Removal scenario. Results had to be computed using only individual sensors and in a combined suite, allowing to identify the pros and cons of each of them, with their specific contributions to the overall performance. Characterization of the infrared sensor was key, as it was the evaluation and analysis of the difficulties and workarounds to test it on-ground. <sup>1</sup></p> <p>Relative chaser-target state estimates are provided by specific image recognition and processing (IRP) algorithms and sensor fusion algorithms in a navigation function (NAV) using sensor data from cameras in the visible spectrum (VIS) and infrared spectrum (IR)) and light detection and ranging (LIDAR) considering as reference mission the Active Debris Removal of ENVISAT (100 \u2026 2 m).</p> <p> </p> Structure of the IRPN system [copyright ESA] <p>Video1: Image-based rendezvous navigation - approaching the target satellite ENVISAT [copyright IfA, TUD]</p> <p>Video2: Image-based rendezvous navigation - VIS camera only / estimated pose = grid overlay [copyright IfA, TUD]:</p>"},{"location":"projects/irpn/#contributions","title":"Contributions","text":"<p>An edge-based pose estimation algorithm is developed for known target satellites as my diploma thesis. The algorithm is base on mono-camera and was evaluated as part of the IPR system. This system is able to estimate the full 6D pose of the considered target object relative to the camera coordinates. It is assumed that a fixed 3D CAD model is available for pre-generating synthetic templates.</p> <p> </p> Principle of the pose estimation algorithm <p>The target is extracted by means of background subtraction technique. Its edges are extracted with Canny detector and then used for matching a set of previously stored templates to retrieve the pose parameters with use of a monocular camera system. Chamfer Matching and Affinity propagation are modified and applied for this purpose.</p> <p> </p> <p>The pose estimation algorithm can probabilistically estimate the full pose based on the result of matching and alignment. The proposed concept can serve as initialization of a frame-by-frame pose tracking. With the help of them, the Rendenzvous maneuver between autonomous approaching Chaser and an uncooperative target comes to be possible.</p> <p> </p> <ol> <li> <p>https://www.esa.int/Enabling_Support/Space_Engineering_Technology/Shaping_the_Future/Image_Recognition_and_Processing_for_Navigation_IRPN\u00a0\u21a9</p> </li> </ol>"},{"location":"projects/klpa/","title":"Small Linear and Planar Direct Drives","text":""},{"location":"projects/klpa/#description","title":"Description","text":"<p>Linear direct drives with a simple single-phase structure allows short travel distances of up to approx. 25 mm, e.g., for automation and handling technology or small machine tools. Special drives with moving permanent magnets and iron-core stator windings enable large forces with low power losses and small installation space. A number of such compact, dynamic and cost-effective linear as well as a new type of planar direct drive were developed, built and tested. They are characterized by<sup>1</sup>:</p> <ul> <li>accelerations up to 35 g,</li> <li>top executives up to over 100 N,</li> <li>integrated roller or spring guides,</li> <li>integrated incremental or absolute displacement sensors</li> <li>with resolutions of currently 0.16 to 1.25 \u00b5m,</li> <li>integrated flatness-based attitude control,</li> <li>sensorless force control,</li> <li>Control commands via EtherCAT, USB or RS-232.</li> </ul> <p> </p> New small linear and planar direct drives with integrated position control [Copyright@ IFTE, TUD]"},{"location":"projects/klpa/#contributions","title":"Contributions","text":"<p>Contributions are the measurement and control of the position of an electrodynamic planar actuator. An optical encoder and an interpolator are used for the positioning of the Platen. The planar actuator consists of four linear motors arranged on the same surface. In this way the platen can be moved in X-direction, Y-direction or about the Z-axis in a limited angular range. For this reason, a multiple input multiple output controller with high dynamic performance is required. To fill the requirements, a path-following control with the robust pole placement is designed and simulated.</p> <p>The novel x-y-\\(\\varphi\\) planar table has been prototyped: video <sup>1</sup>.</p> <ol> <li> <p>https://www.ifte.de/forschung/elektromechanischerEntwurf/kleinantriebe.html\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"projects/t-rox/","title":"Teaching Robots in Saxony","text":""},{"location":"projects/t-rox/#description","title":"Description","text":"<p>The goal of T-RoX project is developing a common, open teaching platform on service robots as part of the RoX initiative. Saxon universities should be able to exchange software for standard robots that can be used in teaching and to develop its software in a simple way for teaching with the help of standardized frameworks.</p> <p>in order to demonstrate the benefits of service robotics in various areas of application, standardized project internships are to be set up for students. They can be used at the universities in Freiberg, Chemnitz and Dresden, which are involved in the RoX initiative.</p> <p>Some hardware platforms for service robots have developed, which are also very interesting for university teaching.</p> <ul> <li>Lego Mindstorms</li> <li>TurtleBot</li> <li>NAO</li> <li>Metralabs Scitos</li> <li>KUKA youBot</li> </ul> <p>They form hardware platforms from \u20ac500 \u2013 \u20ac25,000 that can be programmed using standard operating systems such as Linux and can therefore be used in robot laboratories to train students. The challenge is to create easy-to-use software solutions for these platforms.</p> <p>As part of the T-RoX project, the Chair of Automation Technology is developing a teaching platform consisting of robot hardware and a software environment suitable for controlling, with which certain standard tasks can be demonstrated in teaching.</p> <p>This common, open teaching platform is being developed to demonstrate the benefits of service robotics in various areas of application. The resulting components are to be largely standardized so that the software and teaching resources can be exchanged among Saxon universities.</p>"},{"location":"projects/t-rox/#contributions","title":"Contributions","text":"<ul> <li>Upgraded youBot base for advanced navigation</li> <li>Fine parameter tuning of the joint cascade control</li> <li>Cartesian space control with <code>feedforward</code> and <code>computed torque</code></li> <li>Impedance control</li> <li>SLAM and navigation in ROS</li> </ul> Upgraded youBot base Forward kinematics Inverse kinematics <p>Video: youBot SLAM Demo</p> <p> </p> Booth at OUTPUT <p> </p> Booth at UNI TAG <p>One demo video: Youtube</p>"},{"location":"til/Autogen_definitions_declarations/","title":"Generate definitions or declarations in vscode","text":"<p>Did you spend a lot of time typing out lists of arguments or copying and pasting them while defining functions that have already been declared in a header file, or while declaring functions that have already been defined in a cpp file? The cpp extension in Visual Studio Code could automatically generate a skeleton definition/declaration if it is missing for a function.</p> <p>Functions will be marked with three dots if definition/declaration is missing. Click <code>Quick Fix...</code> or press Ctrl + . to bring up fix context menu. Then you can create a skeleton of the missing definition or declaration.</p> <p>)</p> <p>The generated cpp file looks like:</p> <pre><code>#include \"program_manager_server.hpp\"\n\nuint32_t com::bshg::domain::cleaningrobot::ProgramManager1::SetCleanAll()\n{\n  return 0;\n}\n</code></pre>","tags":["C++","vscode"]},{"location":"til/circular_dependency/","title":"Circular Dependency in C++","text":"<p>Circular dependencies are normally design flaws. But if you have to live along with it, there is a way to go around.</p> <p>Suppose we have class <code>Fool</code> and <code>Bar</code>. If <code>Fool</code> uses <code>Bar</code> and <code>Bar</code> also use <code>Fool</code>, then there is a circular dependency.  In a complex project, it might be not so obvious due to a long chain. In C++, if <code>Fool.h</code> includes <code>Bar.h</code> then <code>Bar.h</code> is not allowed to include <code>Fool.h</code>.  In case of circular dependency, the compiler is not able to determine the size of both <code>Fool</code> and <code>Bar</code> since they contain size-unknown class.</p> <p>The only way for <code>Bar</code> to use <code>Fool</code> is forward declaration. We can forward declare <code>Fool</code> and use pointers or references on <code>Fool</code> without include <code>fool.h</code> in <code>bar.h</code>. Consequently, the compiler doesn't have to know the size of the class but the size of a class pointer. The size of pointer of any class is same, and the compiler won't complain.  Since we still want access to <code>Fool</code>'s public members from the members of <code>Bar</code>, we include <code>fool.h</code> in <code>bar.cpp</code>.</p> fool.h<pre><code># include \"bar.h\"\n\nclass Foo\n{\nprivate:\n  Bar myBar_\n};\n</code></pre> bar.h<pre><code>class Foo; // Forward declaration\n\nClass Bar\n{\nprivate:\n  Fool* myFool_;\n};\n</code></pre> bar.cpp<pre><code>#include \"bar.h\"\n#include \"fool.h\" // include fool.h in .cpp to get access to Fool\n</code></pre> <p>In the end drawbacks of circular dependencies are listed:</p> <ul> <li>Long compilation time. When a file in the cycle is changed, all the other files have to be recompiled.</li> <li>Prone to errors: since several pieces of code are tightly coupled, a change in one will probably break another.</li> <li>Harder to reuse: as many files are dependent on each other, if you want to reuse a file in another project, you must also take the other ones.</li> <li>Harder to debug: as many pieces of codes are coupled, you will have to look at a lot of files if you want to trace back a bug.</li> </ul>","tags":["C++"]},{"location":"til/clear_screen_bash/","title":"Clear Screen in bash","text":"<p>Ctrl + L and <code>clear</code> command can be used to clear the screen of a bash terminal. They behave, however, differently.</p> <p>Ctrl + L will scroll the screen so that the cursor is at the top of the terminal. You can still scroll up and see previous terminal history.</p> <p><code>clear</code> will removes all previous terminal history completely so that you cannot scroll up any more.</p>","tags":["Bash"]},{"location":"til/diagnostic_pragmas/","title":"GCC Diagnostic Pragma","text":"<p>GCC allows the user to selectively enable or disable certain types of diagnostics, and change the kind of the diagnostic. For example, diagnostics might be enabled selectively to treat them as errors depending on which preprocessor macros are defined.</p> <p>Here is a example:</p> <pre><code>// remember current state of the diagnostic\n#pragma GCC diagnostic push\n\n// no diagnostic for return\n#pragma GCC diagnostic ignored \"-Wreturn-type\"\n\nint func1()\n{\n  return;\n}\n\n// restore pushed state of the diagnostic\n#pragma GCC diagnostic push\n\nint func2()\n{\n  return;\n}\n\nint main(int argc, char* argv[])\n{\n  func1();  // no warning\n  func2();  // warning return without value\n}\n</code></pre>","tags":["GCC","C++"]},{"location":"til/emplaceback_pushback/","title":"emplace_back VS push_back","text":"<p>Clang-tidy suggests often to use <code>emplace_back</code> instead of <code>push_back</code>. Why is <code>emplace_back</code> recommended and what is pros and cons of it?</p> <p>push_back</p> <pre><code>void push_back (const value_type&amp; val); void push_back (value_type&amp;&amp; val);\n</code></pre> <p>Adds a new element at the end of the vector, after its current last element. The content of val is copied (or moved) to the new element.</p> <p>This effectively increases the container size by one, which causes an automatic reallocation of the allocated storage space if -and only if- the new vector size surpasses the current vector capacity.</p> <p>If we call <code>push_back</code>,</p> <ul> <li>A constructor will be called to create a temporary object.</li> <li>A copy of the temporary object will be constructed in the memory for the container. (Note that the move constructor will be called if exist because the temporary object is an <code>rvalue</code>, otherwise the copy constructor should be called.</li> <li>The destructor will be called to destroy the temporary object after copy.</li> </ul> <p>emplace_back</p> <p>Appends a new element to the end of the container. The element is constructed through std::allocator_traits::construct, which typically uses placement-new to construct the element in-place at the location provided by the container. The arguments <code>args...</code> are forwarded to the constructor as <code>std::forward&lt;Args&gt;(args)...</code>.</p> <p>If the new <code>size()</code> is greater than capacity() then all iterators and references (including the past-the-end iterator) are invalidated. Otherwise only the past-the-end iterator is invalidated. </p> <p>In contrast to <code>push_back</code>, <code>emplace_back</code> directly takes constructor arguments for objects to be inserted. In other words, the emplacement function avoids constructing and destructing temporary objects. It will be much more efficient to insert large amount of objects or for object that is time consuming to create/destroy.</p> <p>Let's see an example:</p> <pre><code>class Foo {\npublic:\n    Foo(int x, int y) : x_(x), y_(y)\n    {\n        std::cout &lt;&lt; \"Create class\" &lt;&lt; std::endl;\n    }\n\n    ~Foo()\n    {\n        std::cout &lt;&lt; \"Destroy class\" &lt;&lt; std::endl;\n    }\n\n    // Copy Constructor\n    Foo(const Foo&amp; myClass)\n    {\n        std::cout &lt;&lt; \"Copy Constructor Called\" &lt;&lt; std::endl;\n        x_ = myClass.x_;\n    }\n\n    // Move Constructor\n    Foo (Foo&amp;&amp; myClass) noexcept\n    {\n        std::cout &lt;&lt; \"Move Constructor Called\" &lt;&lt; std::endl;\n        x_ = std::move(myClass.x_);\n    }\n\nprivate:\n    int x_ = 0;\n    int y_ = 0;\n\n};\n\nint main()\n{\n    std::vector&lt;Foo&gt; vector;\n    // Reserve space to avoid reallocation\n    vector.reserve(2);\n\n    std::cout &lt;&lt; \"\\n--- push_back ---\" &lt;&lt; std::endl;\n    vector.push_back(Foo(1, 2));\n\n    std::cout &lt;&lt; \"\\n--- emplace_back ---\" &lt;&lt; std::endl;\n    vector.emplace_back(1, 2);\n\n    std::cout &lt;&lt; \"\\n--- Finish ---\" &lt;&lt; std::endl;\n    return 0;\n}\n</code></pre> <p>The output is</p> <pre><code>--- push_back ---\nCreate Class\nMove Constructor Called\nDestroy Class\n\n--- emplace_back ---\nCreate Class\n\n--- Finish ---\nDestroy Class\nDestroy Class\n</code></pre> <p>As described, <code>push_back</code> called the move constructor to make a copy and the destructor to destroy the temporary object while <code>emplace_back</code> constructed the object directly.</p> <p>Should I use <code>emplace_back</code> all the time and forget <code>push_back</code>?</p> <p>NO. </p> <pre><code>vector1.push_back(100); // we can tell it tries to add the number 100 to the end of the vector.\nvector2.emplace_back(100); // Without knowing the type of the vector, we don\u2019t know what constructor is actually invoking.\n</code></pre> <p>If the vector is defined as <pre><code>std::vector&lt;int&gt; vec1;\nstd::vector&lt;std::vector&lt;int&gt;&gt; vec2;\n</code></pre> the <code>emplace_back</code> method in the above will construct a vector of 100 elements.  If this behavior is unexpected, it may take long time for the developers to catch this issues.</p> <p>Quote</p> <p>Very often the performance difference just won\u2019t matter. As always, the rule of thumb is that you should avoid \u201coptimizations\u201d that make the code less safe or less clear, unless the performance benefit is big enough to show up in your application benchmarks.</p>","tags":["C++"]},{"location":"til/git_find/","title":"Search Git Log by Message","text":"<p>To find commit by message, I add an alias in <code>~/.gitconfig</code>:</p> <pre><code>[alias]\n    find = log --all --pretty=\\\"format:%Cgreen%H %Cblue%s\\n%b%Creset\\\" --name-status --grep\n</code></pre> <p>Example</p> <pre><code>git find concurrency\n\n6a786f09b9d56b98df9379e587ce2f8d7428d386 Update concurrency.md\n\nM       docs/blog/cpp/concurrency.md\n\n0381f01063e42b19319cc41ffff9dfe9345dd744 Fix tag of concurrency.md\n\nM       docs/blog/cpp/concurrency.md\n\n48359253b4f101445d3f0ef0632b8c48e64fde5e Merge pull request #6 from leonhartyao/concurrency\nUpdate blog.\n</code></pre>","tags":["git"]},{"location":"til/git_patch/","title":"Create and Apply Patches with Git","text":"","tags":["git"]},{"location":"til/git_patch/#git-diff-git-apply","title":"git diff &amp; git apply","text":"","tags":["git"]},{"location":"til/git_patch/#creat-patches","title":"Creat Patches","text":"<ul> <li>Make your changes in the git repository</li> <li>'git add .'</li> <li><code>git diff --cached &gt; patch_file_name.patch</code></li> </ul>","tags":["git"]},{"location":"til/git_patch/#apply-patches","title":"Apply Patches","text":"<pre><code>cd your_git_repo\ngit apply --check path_to_patch_file.patch\ngit apply path_to_patch_file.patch\n</code></pre>","tags":["git"]},{"location":"til/git_patch/#note","title":"Note","text":"<p>It is a good practice to check before apply patches.</p> <p>Unlike <code>git merge</code>, if there are conflicts when applying a patch with git apply, the process might just fail without any further help. You'd have to manually resolve conflicts and apply the patch again.</p>","tags":["git"]},{"location":"til/git_patch/#git-am","title":"git am","text":"<p><code>git am</code> applies patches generated from commits. It also creates a commit with the metadata (author, date, commit message) from the patch. It provides more sophisticated conflict handling and resolution capabilities, similar to those encountered during a regular merge or rebase. you can easily undo the applied patches with git reset or git reflog, as it automatically creates commits.</p>","tags":["git"]},{"location":"til/git_patch/#create-patches","title":"Create Patches","text":"<p><pre><code>git format-patch -1 HEAD\n</code></pre> This command generates a patch file for the most recent commit (HEAD). The -1 indicates that you want to create a patch for one commit. This will create a file named by the commit like 0001-Commit-message.patch.</p>","tags":["git"]},{"location":"til/git_patch/#apply-patches_1","title":"Apply Patches","text":"<pre><code>cd your_git_repo\ngit am 0001-Commit-message.patch\n</code></pre> <p>This command will apply the patch and automatically create a new commit in your repository with the same commit message, author, and date as the original commit. If there are any conflicts while applying the patch, <code>git am</code> will pause and let you resolve them. The process is similar to resolving conflicts during a merge or rebase.</p> <p>After resolving the conflicts, you would use <code>git am --continue</code> to continue applying pathces. you can abort the process with <code>git am --abort</code>.</p>","tags":["git"]},{"location":"til/mk_key_markup/","title":"Markup keys on a keyboard in Markdown","text":"<p><code>&lt;kbd&gt;foo&lt;/kbd&gt;</code> can be used to markup keys on a keyboard correctly. foo will be key-like.</p> <pre><code>Press &lt;kbd&gt;Ctrl&lt;/kbd&gt; + &lt;kbd&gt;D&lt;/kbd&gt; to scroll down.\n</code></pre> <p>Press Ctrl + D to scroll down.</p>","tags":["Markdown"]},{"location":"til/nodiscard/","title":"Attribute: nodiscard since C++17","text":"<p><code>nodiscard</code> is a attribute introduced by c++17. If a function</p> <ul> <li>declared nodiscard or</li> <li>returning an enumeration or class declared nodiscard by value</li> </ul> <p>the compiler will issue a warning when the function is called from a discarded-value expression other than a cast to void.</p> <p>Here is a example:</p> <pre><code>[[nodiscard]] int foo()\n{\n  return 7;\n}\n\nfoo(); // warning: ignoring return value of function declared with 'nodiscard' attribute\nint bar = foo(); // no warning\nstatic_cast&lt;void&gt;(foo()); // no warning\n</code></pre>","tags":["C++"]},{"location":"til/screenkey/","title":"Show Key Presses on Screen","text":"<p>Screen sharing or recording can't capture the key presses for audience to easiy follow what is happening. In Linux, ScreenKey can show key presses on screen in a subtitle-like manner.  When run, the app will show each key press on screen as you press it.</p> <p>Github: screenkey</p>","tags":["Linux"]},{"location":"til/using_namespace_hpp/","title":"Never use using namespace in Header Files","text":"<p>You should <code>NEVER</code> use <code>using namespace</code> in headers, it can unexpectedly change the meaning of code in any other files that include that header. When you write a header file, you don\u2019t know from which context it will be included. Therefore, if this header contains using directives, you cannot be sure that they will not create ambiguities in that context. Those ambiguities could lead to compilation failures or, worse, to a different function being selected by overload resolution depending on the order of inclusion of headers. Another reason is that there's no way to undo a using namespace.</p> <p>In header files, don't write namespace-level using directives or using declarations; instead, explicitly namespace-qualify all names. You can use <code>using</code> statements within .cpp files without much concern because the scope will be limited to just that file, but never do it before an <code>#include</code> statement.</p>","tags":["C++"]},{"location":"til/weather_cli/","title":"Check Weather Forecast via CLI","text":"<p>You can get weather forecase in your terminal with <code>curl wttr.in</code>:</p> <pre><code>chao@home-ubuntu:~$ $ curl wttr.in\nWeather report: not found\n\n                Overcast\n       .--.     +13(12) \u00b0C     \n    .-(    ).   \u2193 4 km/h       \n   (___.__)__)  16 km          \n                5.5 mm         \n                                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                       \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  Mon 09 Oct \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Morning           \u2502             Noon      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Evening           \u2502             Night            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502      .-.      Patchy light r\u2026\u2502  _`/\"\".-.     Patchy rain po\u2026\u2502  _`/\"\".-.     Patchy rain po\u2026\u2502    \\  /       Partly cloudy  \u2502\n\u2502     (   ).    +8(6) \u00b0C       \u2502   ,\\_(   ).   +9(8) \u00b0C       \u2502   ,\\_(   ).   11 \u00b0C          \u2502  _ /\"\".-.     +7(5) \u00b0C       \u2502\n\u2502    (___(__)   \u2196 11-13 km/h   \u2502    /(___(__)  \u2196 9-10 km/h    \u2502    /(___(__)  \u2191 6-7 km/h     \u2502    \\_(   ).   \u2191 7-10 km/h    \u2502\n\u2502     \u2018 \u2018 \u2018 \u2018   9 km           \u2502      \u2018 \u2018 \u2018 \u2018  10 km          \u2502      \u2018 \u2018 \u2018 \u2018  10 km          \u2502    /(___(__)  10 km          \u2502\n\u2502    \u2018 \u2018 \u2018 \u2018    1.3 mm | 71%   \u2502     \u2018 \u2018 \u2018 \u2018   0.0 mm | 84%   \u2502     \u2018 \u2018 \u2018 \u2018   0.0 mm | 60%   \u2502               0.0 mm | 0%    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                       \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  Tue 10 Oct \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Morning           \u2502             Noon      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Evening           \u2502             Night            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  _`/\"\".-.     Patchy rain po\u2026\u2502      .-.      Light drizzle  \u2502  _`/\"\".-.     Patchy rain po\u2026\u2502  _`/\"\".-.     Patchy rain po\u2026\u2502\n\u2502   ,\\_(   ).   +8(7) \u00b0C       \u2502     (   ).    +8(7) \u00b0C       \u2502   ,\\_(   ).   +9(8) \u00b0C       \u2502   ,\\_(   ).   +2(1) \u00b0C       \u2502\n\u2502    /(___(__)  \u2191 8-9 km/h     \u2502    (___(__)   \u2191 9-10 km/h    \u2502    /(___(__)  \u2197 7-8 km/h     \u2502    /(___(__)  \u2192 5-10 km/h    \u2502\n\u2502      \u2018 \u2018 \u2018 \u2018  10 km          \u2502     \u2018 \u2018 \u2018 \u2018   2 km           \u2502      \u2018 \u2018 \u2018 \u2018  10 km          \u2502      \u2018 \u2018 \u2018 \u2018  10 km          \u2502\n\u2502     \u2018 \u2018 \u2018 \u2018   0.1 mm | 77%   \u2502    \u2018 \u2018 \u2018 \u2018    0.6 mm | 62%   \u2502     \u2018 \u2018 \u2018 \u2018   0.0 mm | 61%   \u2502     \u2018 \u2018 \u2018 \u2018   0.1 mm | 74%   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                       \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  Wed 11 Oct \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Morning           \u2502             Noon      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Evening           \u2502             Night            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     \\   /     Sunny          \u2502     \\   /     Sunny          \u2502     \\   /     Sunny          \u2502     \\   /     Clear          \u2502\n\u2502      .-.      0 \u00b0C           \u2502      .-.      +11(10) \u00b0C     \u2502      .-.      8 \u00b0C           \u2502      .-.      -2(-3) \u00b0C      \u2502\n\u2502   \u2015 (   ) \u2015   \u2197 4-6 km/h     \u2502   \u2015 (   ) \u2015   \u2193 9-10 km/h    \u2502   \u2015 (   ) \u2015   \u2193 7-9 km/h     \u2502   \u2015 (   ) \u2015   \u2199 4-8 km/h     \u2502\n\u2502      `-\u2019      5 km           \u2502      `-\u2019      10 km          \u2502      `-\u2019      10 km          \u2502      `-\u2019      10 km          \u2502\n\u2502     /   \\     0.0 mm | 0%    \u2502     /   \\     0.0 mm | 0%    \u2502     /   \\     0.0 mm | 0%    \u2502     /   \\     0.0 mm | 0%    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>For convience you can set an bash alias</p> <pre><code>alias weather='curl wttr.in'\n</code></pre>","tags":["Linux"]},{"location":"til/where_include/","title":"Put include in .hpp or .cpp","text":"<p>In general, you should only include headers in .hpp files that are needed by those headers.  Otherwise, always include headers only in .cpp files. This keeps compilation time to a minimum and better shows what files are needed.</p> <ul> <li>The contents of a source file aren\u2019t visible to other source files</li> <li>The header exposes the relevant interfaces to sources that will be resolved at linking</li> <li>The header should be able to be included in other source files without adding unforeseen dependencies</li> </ul> <p>In short all of the above means that you should place every include into your source rather than your headers, whenever practical. Headers are better if they have fewer dependencies.</p>","tags":["C++"]},{"location":"til/yaml_string/","title":"How to Escape Characters in YAML Front Matter","text":"<p>To escape characters in YAML front matter, add a <code>&gt;</code> (greater than) symbol and put the line containing the character on a new line.</p> <pre><code>---\ntitle: &gt;\n  Docs: add custom build example for Docsify\n---\n</code></pre> <p>Actually, you should quote all strings that are not simple, alpha-numeric values. You can use double quotes if you want to use escape sequences or use single quotes for literal strings:</p> <pre><code>title: \"[Learning notes.]\"\ntitle: \"\\\"Learning notes.\\\"\"\ntitle: \"Learning notes: cpp\"\n\ntitle: '[Learning notes.]'\ntitle: '\"Learning notes.\"'\ntitle: 'Learning notes: cpp'\n</code></pre>","tags":["MkDocs"]},{"location":"tag/","title":"Tags","text":""},{"location":"tag/#bash","title":"Bash","text":"<ul> <li>Bash File Test Operators</li> <li>Clear Screen in bash</li> </ul>"},{"location":"tag/#c","title":"C++","text":"<ul> <li>Multithreading and Concurrency in C++</li> <li>Recommended VS Code Extensions for Robotic Software Developers</li> <li>Generate definitions or declarations in vscode</li> <li>Circular Dependency in C++</li> <li>GCC Diagnostic Pragma</li> <li>emplace_back VS push_back</li> <li>Attribute: nodiscard since C++17</li> <li>Never use using namespace in Header Files</li> <li>Put include in .hpp or .cpp</li> </ul>"},{"location":"tag/#gcc","title":"GCC","text":"<ul> <li>GCC Diagnostic Pragma</li> </ul>"},{"location":"tag/#linux","title":"Linux","text":"<ul> <li>Show Key Presses on Screen</li> <li>Check Weather Forecast via CLI</li> </ul>"},{"location":"tag/#markdown","title":"Markdown","text":"<ul> <li>Markup keys on a keyboard in Markdown</li> </ul>"},{"location":"tag/#mkdocs","title":"MkDocs","text":"<ul> <li>How to Escape Characters in YAML Front Matter</li> </ul>"},{"location":"tag/#ssh","title":"SSH","text":"<ul> <li>SSH Configuration for Easy and Secure Remote Login</li> </ul>"},{"location":"tag/#git","title":"git","text":"<ul> <li>Find Bug-introducing Commit</li> <li>Git Large File Storage (LFS)</li> <li>Search Git Log by Message</li> <li>Create and Apply Patches with Git</li> </ul>"},{"location":"tag/#vscode","title":"vscode","text":"<ul> <li>Recommended VS Code Extensions for Robotic Software Developers</li> <li>Generate definitions or declarations in vscode</li> </ul>"}]}